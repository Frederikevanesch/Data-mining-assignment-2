{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "gbm = lgb.LGBMRanker()\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file name\n",
    "file_name = 'df_OptionB.csv'\n",
    "\n",
    "# Specify the full file path\n",
    "file_path = r'/Users/frederike/Documents/Artificial inteligence (Master)/Data mining techniques/Data-mining-assignment-2/' + file_name\n",
    "\n",
    "# Read the dataset using pandas\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['srch_id', 'prop_id', 'prop_starrating', 'prop_review_score',\n",
       "       'prop_brand_bool', 'prop_location_score1', 'prop_location_score2',\n",
       "       'prop_log_historical_price', 'price_usd', 'promotion_flag',\n",
       "       'srch_length_of_stay', 'srch_booking_window', 'srch_adults_count',\n",
       "       'srch_room_count', 'srch_saturday_night_bool',\n",
       "       'orig_destination_distance', 'click_bool', 'booking_bool', 'score',\n",
       "       'avg_comp_rate', 'avg_comp_inv', 'abroad_bool', 'children_bool',\n",
       "       'srch_query_affinity_score_low', 'srch_query_affinity_score_high',\n",
       "       'starrating_diff_low', 'starrating_diff_high', 'usd_diff_low',\n",
       "       'usd_diff_high'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='srch_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = list(df['srch_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['score']\n",
    "X=df.drop(['score'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_train = list(X_train['srch_id'].value_counts())\n",
    "group_test = list(X_test['srch_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['click_bool', 'booking_bool', 'srch_id', 'prop_id'], axis=1)\n",
    "X_test = X_test.drop(['click_bool', 'booking_bool', 'srch_id', 'prop_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3173341\n",
      "991670\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frederike/Library/Python/3.9/lib/python/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's ndcg@5: 0.689629\tvalid_1's ndcg@5: 0.925736\n",
      "[2]\ttraining's ndcg@5: 0.694109\tvalid_1's ndcg@5: 0.927052\n",
      "[3]\ttraining's ndcg@5: 0.696001\tvalid_1's ndcg@5: 0.927599\n",
      "[4]\ttraining's ndcg@5: 0.697157\tvalid_1's ndcg@5: 0.927678\n",
      "[5]\ttraining's ndcg@5: 0.698104\tvalid_1's ndcg@5: 0.927891\n",
      "[6]\ttraining's ndcg@5: 0.698614\tvalid_1's ndcg@5: 0.928038\n",
      "[7]\ttraining's ndcg@5: 0.698913\tvalid_1's ndcg@5: 0.928175\n",
      "[8]\ttraining's ndcg@5: 0.699431\tvalid_1's ndcg@5: 0.92829\n",
      "[9]\ttraining's ndcg@5: 0.699865\tvalid_1's ndcg@5: 0.928406\n",
      "[10]\ttraining's ndcg@5: 0.699819\tvalid_1's ndcg@5: 0.928447\n",
      "[11]\ttraining's ndcg@5: 0.700092\tvalid_1's ndcg@5: 0.928517\n",
      "[12]\ttraining's ndcg@5: 0.700256\tvalid_1's ndcg@5: 0.928408\n",
      "[13]\ttraining's ndcg@5: 0.700552\tvalid_1's ndcg@5: 0.92853\n",
      "[14]\ttraining's ndcg@5: 0.700668\tvalid_1's ndcg@5: 0.928556\n",
      "[15]\ttraining's ndcg@5: 0.700879\tvalid_1's ndcg@5: 0.928547\n",
      "[16]\ttraining's ndcg@5: 0.701033\tvalid_1's ndcg@5: 0.928526\n",
      "[17]\ttraining's ndcg@5: 0.701267\tvalid_1's ndcg@5: 0.92873\n",
      "[18]\ttraining's ndcg@5: 0.701721\tvalid_1's ndcg@5: 0.928776\n",
      "[19]\ttraining's ndcg@5: 0.701933\tvalid_1's ndcg@5: 0.928811\n",
      "[20]\ttraining's ndcg@5: 0.701993\tvalid_1's ndcg@5: 0.928907\n",
      "[21]\ttraining's ndcg@5: 0.702042\tvalid_1's ndcg@5: 0.928997\n",
      "[22]\ttraining's ndcg@5: 0.702191\tvalid_1's ndcg@5: 0.928961\n",
      "[23]\ttraining's ndcg@5: 0.702323\tvalid_1's ndcg@5: 0.928973\n",
      "[24]\ttraining's ndcg@5: 0.702425\tvalid_1's ndcg@5: 0.92908\n",
      "[25]\ttraining's ndcg@5: 0.70273\tvalid_1's ndcg@5: 0.92914\n",
      "[26]\ttraining's ndcg@5: 0.702806\tvalid_1's ndcg@5: 0.929162\n",
      "[27]\ttraining's ndcg@5: 0.702872\tvalid_1's ndcg@5: 0.929212\n",
      "[28]\ttraining's ndcg@5: 0.703086\tvalid_1's ndcg@5: 0.92926\n",
      "[29]\ttraining's ndcg@5: 0.703252\tvalid_1's ndcg@5: 0.929301\n",
      "[30]\ttraining's ndcg@5: 0.703534\tvalid_1's ndcg@5: 0.929391\n",
      "[31]\ttraining's ndcg@5: 0.703759\tvalid_1's ndcg@5: 0.929451\n",
      "[32]\ttraining's ndcg@5: 0.703976\tvalid_1's ndcg@5: 0.929463\n",
      "[33]\ttraining's ndcg@5: 0.704047\tvalid_1's ndcg@5: 0.929548\n",
      "[34]\ttraining's ndcg@5: 0.704321\tvalid_1's ndcg@5: 0.92952\n",
      "[35]\ttraining's ndcg@5: 0.704595\tvalid_1's ndcg@5: 0.929585\n",
      "[36]\ttraining's ndcg@5: 0.704593\tvalid_1's ndcg@5: 0.929553\n",
      "[37]\ttraining's ndcg@5: 0.704705\tvalid_1's ndcg@5: 0.929631\n",
      "[38]\ttraining's ndcg@5: 0.704864\tvalid_1's ndcg@5: 0.929629\n",
      "[39]\ttraining's ndcg@5: 0.704979\tvalid_1's ndcg@5: 0.929683\n",
      "[40]\ttraining's ndcg@5: 0.705229\tvalid_1's ndcg@5: 0.929699\n",
      "[41]\ttraining's ndcg@5: 0.705419\tvalid_1's ndcg@5: 0.929708\n",
      "[42]\ttraining's ndcg@5: 0.705644\tvalid_1's ndcg@5: 0.929722\n",
      "[43]\ttraining's ndcg@5: 0.705745\tvalid_1's ndcg@5: 0.929781\n",
      "[44]\ttraining's ndcg@5: 0.705798\tvalid_1's ndcg@5: 0.929826\n",
      "[45]\ttraining's ndcg@5: 0.706017\tvalid_1's ndcg@5: 0.929869\n",
      "[46]\ttraining's ndcg@5: 0.706108\tvalid_1's ndcg@5: 0.929922\n",
      "[47]\ttraining's ndcg@5: 0.706244\tvalid_1's ndcg@5: 0.929913\n",
      "[48]\ttraining's ndcg@5: 0.706491\tvalid_1's ndcg@5: 0.92994\n",
      "[49]\ttraining's ndcg@5: 0.706614\tvalid_1's ndcg@5: 0.929933\n",
      "[50]\ttraining's ndcg@5: 0.706757\tvalid_1's ndcg@5: 0.929999\n",
      "[51]\ttraining's ndcg@5: 0.706983\tvalid_1's ndcg@5: 0.930062\n",
      "[52]\ttraining's ndcg@5: 0.707087\tvalid_1's ndcg@5: 0.930032\n",
      "[53]\ttraining's ndcg@5: 0.70716\tvalid_1's ndcg@5: 0.930094\n",
      "[54]\ttraining's ndcg@5: 0.707293\tvalid_1's ndcg@5: 0.930095\n",
      "[55]\ttraining's ndcg@5: 0.707487\tvalid_1's ndcg@5: 0.930124\n",
      "[56]\ttraining's ndcg@5: 0.707575\tvalid_1's ndcg@5: 0.930188\n",
      "[57]\ttraining's ndcg@5: 0.707705\tvalid_1's ndcg@5: 0.930261\n",
      "[58]\ttraining's ndcg@5: 0.70776\tvalid_1's ndcg@5: 0.930316\n",
      "[59]\ttraining's ndcg@5: 0.707859\tvalid_1's ndcg@5: 0.930359\n",
      "[60]\ttraining's ndcg@5: 0.708011\tvalid_1's ndcg@5: 0.930372\n",
      "[61]\ttraining's ndcg@5: 0.708112\tvalid_1's ndcg@5: 0.930408\n",
      "[62]\ttraining's ndcg@5: 0.708217\tvalid_1's ndcg@5: 0.930389\n",
      "[63]\ttraining's ndcg@5: 0.708373\tvalid_1's ndcg@5: 0.930405\n",
      "[64]\ttraining's ndcg@5: 0.708384\tvalid_1's ndcg@5: 0.930373\n",
      "[65]\ttraining's ndcg@5: 0.708646\tvalid_1's ndcg@5: 0.930427\n",
      "[66]\ttraining's ndcg@5: 0.708745\tvalid_1's ndcg@5: 0.930413\n",
      "[67]\ttraining's ndcg@5: 0.70881\tvalid_1's ndcg@5: 0.930412\n",
      "[68]\ttraining's ndcg@5: 0.708878\tvalid_1's ndcg@5: 0.930436\n",
      "[69]\ttraining's ndcg@5: 0.70894\tvalid_1's ndcg@5: 0.930471\n",
      "[70]\ttraining's ndcg@5: 0.70897\tvalid_1's ndcg@5: 0.930485\n",
      "[71]\ttraining's ndcg@5: 0.70908\tvalid_1's ndcg@5: 0.930491\n",
      "[72]\ttraining's ndcg@5: 0.709199\tvalid_1's ndcg@5: 0.930523\n",
      "[73]\ttraining's ndcg@5: 0.709289\tvalid_1's ndcg@5: 0.930529\n",
      "[74]\ttraining's ndcg@5: 0.709309\tvalid_1's ndcg@5: 0.930526\n",
      "[75]\ttraining's ndcg@5: 0.709444\tvalid_1's ndcg@5: 0.930525\n",
      "[76]\ttraining's ndcg@5: 0.709521\tvalid_1's ndcg@5: 0.930576\n",
      "[77]\ttraining's ndcg@5: 0.709551\tvalid_1's ndcg@5: 0.930594\n",
      "[78]\ttraining's ndcg@5: 0.70964\tvalid_1's ndcg@5: 0.930648\n",
      "[79]\ttraining's ndcg@5: 0.709739\tvalid_1's ndcg@5: 0.930649\n",
      "[80]\ttraining's ndcg@5: 0.709822\tvalid_1's ndcg@5: 0.930585\n",
      "[81]\ttraining's ndcg@5: 0.710004\tvalid_1's ndcg@5: 0.930589\n",
      "[82]\ttraining's ndcg@5: 0.710125\tvalid_1's ndcg@5: 0.930583\n",
      "[83]\ttraining's ndcg@5: 0.710236\tvalid_1's ndcg@5: 0.930617\n",
      "[84]\ttraining's ndcg@5: 0.710303\tvalid_1's ndcg@5: 0.93061\n",
      "[85]\ttraining's ndcg@5: 0.710433\tvalid_1's ndcg@5: 0.930596\n",
      "[86]\ttraining's ndcg@5: 0.710571\tvalid_1's ndcg@5: 0.93059\n",
      "[87]\ttraining's ndcg@5: 0.710673\tvalid_1's ndcg@5: 0.930581\n",
      "[88]\ttraining's ndcg@5: 0.710706\tvalid_1's ndcg@5: 0.930596\n",
      "[89]\ttraining's ndcg@5: 0.7108\tvalid_1's ndcg@5: 0.9306\n",
      "[90]\ttraining's ndcg@5: 0.710842\tvalid_1's ndcg@5: 0.930636\n",
      "[91]\ttraining's ndcg@5: 0.710921\tvalid_1's ndcg@5: 0.930664\n",
      "[92]\ttraining's ndcg@5: 0.711021\tvalid_1's ndcg@5: 0.930679\n",
      "[93]\ttraining's ndcg@5: 0.711144\tvalid_1's ndcg@5: 0.930685\n",
      "[94]\ttraining's ndcg@5: 0.711216\tvalid_1's ndcg@5: 0.930668\n",
      "[95]\ttraining's ndcg@5: 0.711248\tvalid_1's ndcg@5: 0.930689\n",
      "[96]\ttraining's ndcg@5: 0.711295\tvalid_1's ndcg@5: 0.930671\n",
      "[97]\ttraining's ndcg@5: 0.71141\tvalid_1's ndcg@5: 0.930652\n",
      "[98]\ttraining's ndcg@5: 0.711504\tvalid_1's ndcg@5: 0.930677\n",
      "[99]\ttraining's ndcg@5: 0.711569\tvalid_1's ndcg@5: 0.930698\n",
      "[100]\ttraining's ndcg@5: 0.711648\tvalid_1's ndcg@5: 0.930723\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRanker()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRanker</label><div class=\"sk-toggleable__content\"><pre>LGBMRanker()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRanker()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.fit(X_train, y_train, group=group_train,\n",
    "        eval_set=[(X_train, y_train), (X_test, y_test)], eval_group=[group_train, group_test],\n",
    "        eval_at=5, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>prop_location_score1</th>\n",
       "      <th>prop_location_score2</th>\n",
       "      <th>prop_log_historical_price</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>promotion_flag</th>\n",
       "      <th>srch_length_of_stay</th>\n",
       "      <th>srch_booking_window</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_comp_inv</th>\n",
       "      <th>abroad_bool</th>\n",
       "      <th>children_bool</th>\n",
       "      <th>srch_query_affinity_score_low</th>\n",
       "      <th>srch_query_affinity_score_high</th>\n",
       "      <th>starrating_diff_low</th>\n",
       "      <th>starrating_diff_high</th>\n",
       "      <th>usd_diff_low</th>\n",
       "      <th>usd_diff_high</th>\n",
       "      <th>predicted_ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1957972</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>4.91</td>\n",
       "      <td>83.29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.172491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4659986</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.4986</td>\n",
       "      <td>4.92</td>\n",
       "      <td>83.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.115949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714663</th>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>4.75</td>\n",
       "      <td>78.86</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.099707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4941851</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>4.82</td>\n",
       "      <td>97.91</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.098050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902160</th>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.8897</td>\n",
       "      <td>5.18</td>\n",
       "      <td>82.26</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.086057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685722</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>4.22</td>\n",
       "      <td>169.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.828576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896574</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.02</td>\n",
       "      <td>69.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.831172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725038</th>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>4.09</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.831806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4160194</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.11</td>\n",
       "      <td>78.82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.849138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772788</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>4.17</td>\n",
       "      <td>91.20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.887489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>991670 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prop_starrating  prop_review_score  prop_brand_bool  \\\n",
       "1957972                4                4.0                1   \n",
       "4659986                4                5.0                1   \n",
       "714663                 4                4.5                0   \n",
       "4941851                4                4.0                0   \n",
       "2902160                4                4.5                1   \n",
       "...                  ...                ...              ...   \n",
       "3685722                3                5.0                1   \n",
       "1896574                0                2.0                1   \n",
       "2725038                2                3.5                1   \n",
       "4160194                0                2.0                1   \n",
       "1772788                2                1.0                1   \n",
       "\n",
       "         prop_location_score1  prop_location_score2  \\\n",
       "1957972                  0.00                0.8571   \n",
       "4659986                  1.61                0.4986   \n",
       "714663                   1.10                0.9091   \n",
       "4941851                  0.69                0.9401   \n",
       "2902160                  1.61                0.8897   \n",
       "...                       ...                   ...   \n",
       "3685722                  0.00                0.0002   \n",
       "1896574                  2.40                0.0000   \n",
       "2725038                  0.00                0.0015   \n",
       "4160194                  2.40                0.0000   \n",
       "1772788                  1.10                0.0002   \n",
       "\n",
       "         prop_log_historical_price  price_usd  promotion_flag  \\\n",
       "1957972                       4.91      83.29               0   \n",
       "4659986                       4.92      83.00               1   \n",
       "714663                        4.75      78.86               0   \n",
       "4941851                       4.82      97.91               1   \n",
       "2902160                       5.18      82.26               1   \n",
       "...                            ...        ...             ...   \n",
       "3685722                       4.22     169.00               0   \n",
       "1896574                       5.02      69.00               0   \n",
       "2725038                       4.09      60.00               0   \n",
       "4160194                       5.11      78.82               0   \n",
       "1772788                       4.17      91.20               0   \n",
       "\n",
       "         srch_length_of_stay  srch_booking_window  ...  avg_comp_inv  \\\n",
       "1957972                    1                   44  ...           0.0   \n",
       "4659986                    1                   13  ...           0.0   \n",
       "714663                     2                    5  ...           0.0   \n",
       "4941851                    2                    1  ...           0.0   \n",
       "2902160                    7                    8  ...           0.0   \n",
       "...                      ...                  ...  ...           ...   \n",
       "3685722                    1                    1  ...           0.0   \n",
       "1896574                    1                    8  ...           0.0   \n",
       "2725038                    2                    5  ...           0.0   \n",
       "4160194                    1                    0  ...           0.0   \n",
       "1772788                    1                   14  ...           0.0   \n",
       "\n",
       "         abroad_bool  children_bool  srch_query_affinity_score_low  \\\n",
       "1957972            0              0                              0   \n",
       "4659986            0              1                              0   \n",
       "714663             0              0                              0   \n",
       "4941851            0              0                              0   \n",
       "2902160            1              1                              0   \n",
       "...              ...            ...                            ...   \n",
       "3685722            0              0                              0   \n",
       "1896574            1              0                              0   \n",
       "2725038            0              0                              0   \n",
       "4160194            0              0                              0   \n",
       "1772788            0              0                              0   \n",
       "\n",
       "         srch_query_affinity_score_high  starrating_diff_low  \\\n",
       "1957972                               0                    0   \n",
       "4659986                               0                    0   \n",
       "714663                                0                    0   \n",
       "4941851                               0                    0   \n",
       "2902160                               0                    0   \n",
       "...                                 ...                  ...   \n",
       "3685722                               0                    0   \n",
       "1896574                               0                    0   \n",
       "2725038                               0                    0   \n",
       "4160194                               0                    0   \n",
       "1772788                               0                    0   \n",
       "\n",
       "         starrating_diff_high  usd_diff_low  usd_diff_high  predicted_ranking  \n",
       "1957972                     0             0              0           3.172491  \n",
       "4659986                     0             0              0           3.115949  \n",
       "714663                      0             0              0           3.099707  \n",
       "4941851                     0             0              0           3.098050  \n",
       "2902160                     0             0              0           3.086057  \n",
       "...                       ...           ...            ...                ...  \n",
       "3685722                     0             0              0          -1.828576  \n",
       "1896574                     1             0              1          -1.831172  \n",
       "2725038                     1             0              1          -1.831806  \n",
       "4160194                     1             0              1          -1.849138  \n",
       "1772788                     1             0              1          -1.887489  \n",
       "\n",
       "[991670 rows x 25 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[\"predicted_ranking\"] = test_pred\n",
    "X_test.sort_values(\"predicted_ranking\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'df_testB.csv'\n",
    "file_path = r'/Users/frederike/Documents/Artificial inteligence (Master)/Data mining techniques/Data-mining-assignment-2/' + file_name\n",
    "df_test = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort test set \n",
    "df_test = df_test.sort_values(by='srch_id')\n",
    "\n",
    "# Creating group list to use in test set prediction\n",
    "group = list(df_test['srch_id'].value_counts())\n",
    "\n",
    "# Storing the removed columns in a separate DataFrame\n",
    "df_test_columns_removed = df_test[['srch_id', 'prop_id']].copy()\n",
    "\n",
    "# Create a new DataFrame by dropping the desired columns\n",
    "df_test = df_test.drop(columns=['srch_id', 'prop_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply model to test set\n",
    "pred = gbm.predict(df_test, group=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to test set\n",
    "df_test[\"predicted_ranking\"] = pred\n",
    "\n",
    "# Adding the columns back\n",
    "df_test['srch_id'] = df_test_columns_removed['srch_id']\n",
    "df_test['prop_id'] = df_test_columns_removed['prop_id']\n",
    "\n",
    "# Sort the dataframe by `srch_id` and `predicted_ranking` in descending order\n",
    "test_sorted = df_test.sort_values(['srch_id', 'predicted_ranking'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4959183\n"
     ]
    }
   ],
   "source": [
    "result = test_sorted[['srch_id', 'prop_id']]\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('LambdaMart_result_unbalanced.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
